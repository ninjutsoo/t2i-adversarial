# Trustworthiness of Generative AI<span id="head"/>

A collection of papers and resources on the adversarial robustness of Text-to-Image Diffusion Models.

As generative AI rapidly evolves, exemplified by models like Stable Diffusion, understanding their trustworthiness against adversarial attacks becomes crucial. This repository gathers significant contributions that explore word-level adversarial impacts on these models, particularly through the lens of the CLIP mechanism. It serves as a curated knowledge base for advancing the safety and reliability of generative AI systems in the face of nuanced adversarial challenges.

## Overview

This repository offers a curated selection of research on the adversarial robustness of Text-to-Image Diffusion Models, with a focus on word-level adversarial attacks. It aims to enhance the trustworthiness of generative AI by addressing the vulnerabilities exposed by subtle textual manipulations.
