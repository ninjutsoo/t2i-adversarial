# Trustworthiness of Generative AI<span id="head"/>

A collection of papers and resources on the adversarial robustness of Text-to-Image Diffusion Models.

As generative AI rapidly evolves, exemplified by models like Stable Diffusion, understanding their trustworthiness against adversarial attacks becomes crucial. This repository gathers significant contributions that explore word-level adversarial impacts on these models, particularly through the lens of the CLIP mechanism. It serves as a curated knowledge base for advancing the safety and reliability of generative AI systems in the face of nuanced adversarial challenges.

## Overview

This repository offers a curated selection of research on the adversarial robustness of Text-to-Image Diffusion Models, with a focus on word-level adversarial attacks. It aims to enhance the trustworthiness of generative AI by addressing the vulnerabilities exposed by subtle textual manipulations.

## Table of Contents<span id="table-of-contents"/>
* [Trustworthiness of Generative AI](#head)
   * [Table of Contents](#table-of-contents)
   * [T2I Generative AI](#t2i-generative)
     * [T2I Attacks](#t2i-generative-attacks)
       * [Papers](#t2i-generative-attacks-papers)
       * [Blogs](#t2i-generative-attacks-blogs)
       * [Datasets](#t2i-generative-attacks-datasets)

## T2I Generative AI<span id="t2i-generative"/>
### T2I Attacks<span id="t2i-generative-attacks"/>
#### Papers <span id="t2i-generative-attacks-papers"/>
* A Pilot Study of Query-Free Adversarial Attack against Stable Diffusion [link](https://arxiv.org/abs/2303.16378)
* Black Box Adversarial Prompting for Foundation Models [link](https://arxiv.org/abs/2302.04237)
* Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks [link](https://arxiv.org/abs/2306.13103)
* https://arxiv.org/abs/2208.04135
* Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks [link](https://arxiv.org/abs/2208.04135)
#### Blogs <span id="t2i-generative-attacks-blogs"/>
* This new data poisoning tool lets artists fight back against generative AI [link](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/amp/)
#### Datasets <span id="t2i-generative-attacks-datasets"/>
* SBU Captions [link](https://huggingface.co/datasets/sbu_captions)
* DiffusionDB [link](https://huggingface.co/datasets/poloclub/diffusiondb)
* LAION COCO [link](https://huggingface.co/datasets/laion/laion-coco)
